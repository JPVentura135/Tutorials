{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a quick fit using astropy.modeling\n",
    "\n",
    "## Authors\n",
    "Rocio Kiman\n",
    "\n",
    "## Learning Goals\n",
    "* Know basic models in Astropy Modeling\n",
    "* Be able to make a quick fit of your data\n",
    "* Visualize the fit\n",
    "\n",
    "## Keywords\n",
    "Modeling, Fit \n",
    "\n",
    "## Summary\n",
    "In this tutorial, we will become familiar with the models available in `astropy.modeling` and learn how to make a quick fit of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of available models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Gaussian1D`\n",
    "* `Trapezoid1D`\n",
    "* `Polynomial1D`\n",
    "* `Sine1D`\n",
    "* `Linear1D`\n",
    "* The [list](http://docs.astropy.org/en/stable/modeling/#module-astropy.modeling.functional_models) continues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of available fitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `LinearLSQFitter()`       A class performing a linear least square fitting.\n",
    "* `SLSQPLSQFitter()`        SLSQP optimization algorithm and least squares statistic.\n",
    "* `LevMarLSQFitter()`       Levenberg-Marquardt algorithm and least squares statistic.\n",
    "* `SimplexLSQFitter()`      Simplex algorithm and least squares statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check http://docs.astropy.org/en/stable/modeling/ for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.modeling import models, fitting\n",
    "from astroquery.vizier import Vizier\n",
    "# Make plots display in notebooks\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Fit a Lineal model: Three steps to fit data using astropy.modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start with a lineal fit to real data. This data comes from the paper [Bhardwaj et al. 2017](https://ui.adsabs.harvard.edu/?#abs/2017A%26A...605A.100B). To get it, we are going to import it from [Vizier](http://vizier.u-strasbg.fr/viz-bin/VizieR) using [astroquery](http://astroquery.readthedocs.io/en/latest/vizier/vizier.html). You don't need internet for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Vizier.get_catalogs('J/A+A/605/A100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This catalog has a lot of information, so we are going to put a special name to the arrays we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = np.array(catalog[0]['Period']) \n",
    "log_period = np.log10(period)\n",
    "k_mag = np.array(catalog[0]['__Ksmag_'])\n",
    "k_mag_err = np.array(catalog[0]['e__Ksmag_'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to plot this data, as any astronomer would do when they do research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(log_period,k_mag,k_mag_err,fmt='k.')\n",
    "plt.xlabel(r'$\\log_{10}$(Period [days])')\n",
    "plt.ylabel('Ks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this looks like a line. To probe it, we want to make a fit to the data. This is where `astropy.modeling` is useful. We are going to understand how in three simple lines we can make any fit we want. But let's start with the linear fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start with the first step: Set up the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to choose which model we are going to fit to our data. As we said before, our data looks like a linear relation, so we are going to use a polynomial of degree 1. If you want, you can use `Linear1D` and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Polynomial1D(degree=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second step: Set up the fitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second we are going to choose the fitter we want to use. This choise is basically which method we want to use to fit the model to the data. In this case we are going to use a the [*Linear Least Square Fitting*](https://www.mathworks.com/help/curvefit/least-squares-fitting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = fitting.LinearLSQFitter() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third step: Fit the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we give to our **fitter** (method to fit the data) the **model** and the **data** to perform the fit. Note that we are adding weights: This means that values with higher error will have smaller weight (less importance) in the fit, and the contrary for point with smaller error. This way of fitting is called *Weighted Least Squares* and you can find more information about it [here](https://www.mathworks.com/help/curvefit/least-squares-fitting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_fit = fitter(model, log_period, k_mag, weights=1.0/k_mag_err**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check what is this new element we created: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see it has the coefficients for our fit were: `y = c0 + c1*x`.\n",
    "\n",
    "And that's it!\n",
    "\n",
    "We can easily evaluate the fit for our particular x axis by doing `best_fit(x)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(log_period,k_mag,k_mag_err,fmt='k.')\n",
    "plt.plot(log_period, best_fit(log_period), color='g', linewidth=3)  \n",
    "plt.xlabel(r'$\\log_{10}$(Period [days])')\n",
    "plt.ylabel('Ks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Remember, with three lines you can have your fit:\n",
    "    > model\n",
    "    > fitter\n",
    "    > perform fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Fit a Polynomial model: Choose fitter wisely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For second example, lets fit a polynomial of degree more than 1. In this case, we are going to create fake data to make the fit. Note that we are adding gaussian noise to the data with the function `np.random.normal(0,2)` which gives a random number from a gaussian distribution with mean 0 and width 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "x1 = np.linspace(0, 4, N)  # Makes an array from 0 to 4 of N elements\n",
    "y1 = x1**3 - 6*x1**2 + 12*x1 - 9 \n",
    "# Now we add some noise to the data\n",
    "y1 = np.array([y_point + np.random.normal(0,2) for y_point in y1])  \n",
    "sigma = 1.5\n",
    "y1_err = np.ones(N)*sigma "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot it to see how it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x1, y1, yerr=y1_err,fmt='k.')\n",
    "plt.xlabel('$x_1$')  \n",
    "plt.ylabel('$y_1$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit this data lets remember the three steps: model, fitter and perform fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_poly = models.Polynomial1D(degree=3)\n",
    "fitter_poly = fitting.LinearLSQFitter() \n",
    "best_fit_poly = fitter_poly(model_poly, x1, y1, weights = 1.0/y1_err**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_fit_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we don't want to use that fitter (method) to fit the data? Lets use the same model but with a different fitter: `SimplexLSQFitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter_poly_2 = fitting.SimplexLSQFitter()\n",
    "best_fit_poly_2 = fitter_poly_2(model_poly, x1, y1, weights = 1.0/y1_err**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_fit_poly_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to check which method is best is calculating the [*Reduce Chi Square Value*](https://en.wikipedia.org/wiki/Reduced_chi-squared_statistic). Lets define a function to do that because we are going to use it several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_reduce_chi_square(fit, x, y, yerr, N, n_free):\n",
    "    '''\n",
    "    fit (array) values for the fit\n",
    "    x,y,yerr (arrays) data\n",
    "    N total number of points\n",
    "    n_free number of parameters we are fitting\n",
    "    '''\n",
    "    return 1.0/(N-n_free)*sum(((fit - y)/yerr)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_chi_squared = calc_reduce_chi_square(best_fit_poly(x1), x1, y1, y1_err, N, 4)\n",
    "print('Reduce Chi Squared with LinearLSQFitter: {}'.format(reduce_chi_squared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_chi_squared = calc_reduce_chi_square(best_fit_poly_2(x1), x1, y1, y1_err, N, 4)\n",
    "print('Reduce Chi Squared with SimplexLSQFitter: {}'.format(reduce_chi_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the *Reduce Chi Square* for the first fit is closer to one, which means this fit is better. Note that when we used the second fitter we got a warning saying that as the model is linear, we should use a linear method to fit the data (linear fitter) and that the iteration were not enough to make a good fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x1, y1, yerr=y1_err,fmt='k.')\n",
    "plt.plot(x1, best_fit_poly(x1), color='r', linewidth=3, label='LinearLSQFitter()')  \n",
    "plt.plot(x1, best_fit_poly_2(x1), color='g', linewidth=3, label='SimplexLSQFitter()')\n",
    "plt.xlabel(r'$\\log_{10}$(Period [days])')\n",
    "plt.ylabel('Ks')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are as espected, the fit performed with the linear fitter is better than the second one, non linear. \n",
    "\n",
    "**Conclusion:** Pay attention when you choose the fitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Fit a Gaussian: Lets compare to scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe some of you know that scipy has the function [`scipy.optimize.curve_fit`](https://docs.scipy.org/doc/scipy-1.0.0/reference/generated/scipy.optimize.curve_fit.html) to fit in a similar way we are doing things. Lets compare the two methods with fake data in the shape of a gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma, amplitude = 0.0, 10.0, 10.0\n",
    "N2 = 100\n",
    "x2 = np.linspace(-30, 30, N)\n",
    "y2 = amplitude * np.exp(-(x2-mu)**2 / (2*sigma**2))\n",
    "y2 = np.array([y_point + np.random.normal(0, 1) for y_point in y2])\n",
    "sigma = 1\n",
    "y2_err = np.ones(N)*sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x2, y2, yerr=y2_err, fmt='k.')\n",
    "plt.xlabel('$x_2$')\n",
    "plt.ylabel('$y_2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do our three lines to make the fit we want. Note that we are not going to use the same linear fitter we were using, but one that is not linear (`LevMarLSQFitter`) because now our model requiers it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gauss = models.Gaussian1D()\n",
    "fitter_gauss = fitting.LevMarLSQFitter()\n",
    "best_fit_gauss = fitter_gauss(model_gauss, x2, y2, weights=1/y2_err**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_fit_gauss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the errors on the parameters, for this fitter, we can use `fitter.fit_info['param_cov']` which gives the [covariance matrix](http://mathworld.wolfram.com/CovarianceMatrix.html), and the elements in the diagonal are the errors. We can check the order of the parameters using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gauss.param_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_diag = np.diag(fitter_gauss.fit_info['param_cov'])\n",
    "print(cov_diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Amplitude: {} +\\- {}'.format(best_fit_gauss.amplitude.value, np.sqrt(cov_diag[0])))\n",
    "print('Mean: {} +\\- {}'.format(best_fit_gauss.mean.value, np.sqrt(cov_diag[1])))\n",
    "print('Standard Deviation: {} +\\- {}'.format(best_fit_gauss.stddev.value, np.sqrt(cov_diag[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets do the same fit but using the method with scipy, and compare the results the same way we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def f(x,a,b,c):\n",
    "    return a * np.exp(-(x-b)**2/(2.0*c**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_opt, p_cov = scipy.optimize.curve_fit(f,x2, y2, sigma=y1_err)\n",
    "a,b,c = p_opt\n",
    "best_fit_gauss_2 = f(x2,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Amplitude: {} +\\- {}'.format(p_opt[0], np.sqrt(p_cov[0,0])))\n",
    "print('Mean: {} +\\- {}'.format(p_opt[1], np.sqrt(p_cov[1,1])))\n",
    "print('Standard Deviation: {} +\\- {}'.format(p_opt[2], np.sqrt(p_cov[2,2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_chi_squared = calc_reduce_chi_square(best_fit_gauss(x2), x2, y2, y2_err, N2, 3)\n",
    "print('Reduce Chi Squared using astropy.modeling: {}'.format(reduce_chi_squared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_chi_squared = calc_reduce_chi_square(best_fit_gauss_2, x2, y2, y2_err, N2, 3)\n",
    "print('Reduce Chi Squared using scipy: {}'.format(reduce_chi_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there is a very small difference in the *Reduce Chi Squared*, but the method with scipy require us to know the function we wanted to fit. In the case of `astropy.modeling`, if you check again the fits we made before, the only thing we changed to make different fits was the name of the model and the fitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x2, y2, yerr=y2_err, fmt='k.')\n",
    "plt.plot(x2, best_fit_gauss(x2), 'g-', linewidth=6, label='astropy.modeling')\n",
    "plt.plot(x2, best_fit_gauss_2, 'r-', linewidth=2, label='scipy')\n",
    "plt.xlabel('$x_2$')\n",
    "plt.ylabel('$y_2$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Choose the method most convenient for every case you need to fit. We recomend astropy.modeling to make quick fits of known functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Exercise: Your turn to choose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: For the next data: \n",
    "* Choose model and fitter to fit this data.\n",
    "* Compare different options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N3 = 100\n",
    "x3 = np.linspace(0, 3, N3)\n",
    "y3 = 5.0 * np.sin(2 * np.pi * x3)\n",
    "y3 = np.array([y_point + np.random.normal(0, 1) for y_point in y3])\n",
    "sigma = 1.5\n",
    "y3_err = np.ones(N)*sigma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.errorbar(x3, y3, yerr=y3_err, fmt='k.')\n",
    "plt.xlabel('$x_3$')\n",
    "plt.ylabel('$y_3$')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
